{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time \n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = '/Users/trey/Image-Scraping/scraping/chromedriver'\n",
    "wd = webdriver.Chrome(executable_path=DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRIVER_PATH = '/Users/trey/Image-Scraping/scraping/chromedriver'\n",
    "wd = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "    \n",
    "search_url = \"https://www.google.com/search?q={q}&sxsrf=ALeKk02zAb9RaNNb-qSenTEJh1i2XX480w:1613489053802&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjChJqP2-7uAhVyTTABHdX0CPoQ_AUoAXoECAcQAw&biw=767&bih=841\"\n",
    "    \n",
    "wd.get(search_url.format(q='tree'))\n",
    "body = wd.find_element_by_tag_name(\"body\")\n",
    "   \n",
    "main = []\n",
    "# iterating past 49 elements after this works of creat\n",
    "    # a variable that holds\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "data = wd.find_elements_by_class_name(\"rg_i.Q4LuWd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = [data[i].get_attribute('src') for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "links1 = [data[i].get_attribute('data-src') for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import selenium \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def scrape(search_name,web_driver=wd):\n",
    "    DRIVER_PATH = '/Users/trey/Image-Scraping/scraping/chromedriver'\n",
    "    wd = webdriver.Chrome(executable_path=DRIVER_PATH)\n",
    "    \n",
    "    search_url = \"https://www.google.com/search?q={q}&sxsrf=ALeKk02zAb9RaNNb-qSenTEJh1i2XX480w:1613489053802&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjChJqP2-7uAhVyTTABHdX0CPoQ_AUoAXoECAcQAw&biw=767&bih=841\"\n",
    "    \n",
    "    wd.get(search_url.format(q=search_name))\n",
    "    body = wd.find_element_by_tag_name(\"body\")\n",
    "   \n",
    "    main = []\n",
    "    for i in range(1):\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        data = wd.find_elements_by_class_name(\"rg_i.Q4LuWd\")\n",
    "        #links = data.get_attribute('src')\n",
    "        #main.append(data)#.get_attribute(\"src\")\n",
    "        #time.sleep(1.75)\n",
    "    #for i in range(1\n",
    "        \n",
    "    #click = wd.find_element_by_class_name(\"YstHxe\")\n",
    "    #click.click()\n",
    "    #time.sleep(5)\n",
    "    \n",
    "    #for i in range(1):\n",
    "    #    body.send_keys(Keys.PAGE_DOWN)\n",
    "        #main.append(wd.find_elements_by_class_name(\"rg_i.Q4LuWd\"))\n",
    "    #    time.sleep(1.75)\n",
    "    #time.sleep(2.5)\n",
    "    #main = wd.find_elements_by_class_name(\"rg_i.Q4LuWd\")\n",
    "    return links\n",
    "    wd.quit()\n",
    "\n",
    "\n",
    "def sort(main):\n",
    "    links = [main[i].get_attribute('src') for i in range(len(main))]\n",
    "    beginning = []\n",
    "    for i in main:\n",
    "        beginning_src_link = beginning.append(i[0:6])\n",
    "    return beginning\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def correct(mains):\n",
    "    imagess = []\n",
    "    for image in images:\n",
    "        if image[0:4] == 'data':\n",
    "            new = image.replace(\"data:image/jpeg;base64,\",\"\")\n",
    "            if new[-2:] != '==':\n",
    "                new_edit = new + '=='\n",
    "                image = (Image.open(BytesIO(base64.b64decode(new_edit)))).resize((150,150))\n",
    "                imagess.append(image)\n",
    "            else:\n",
    "                image = (Image.open(BytesIO(base64.b64decode(new)))).resize((150,150))\n",
    "                imagess.append(image)\n",
    "        if image[0:4] == 'http':\n",
    "            new = requests.get(image)\n",
    "            image = Image.open(BytesIO(image.content))\n",
    "            imagess.append(image)\n",
    "    return images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save(images):\n",
    "    os.mkdir('Images')\n",
    "    os.mkdir('Images/regular')\n",
    "    index = 0 \n",
    "    for i in images:\n",
    "        i.save('Images/regular'+'/'+str(index)+'.jpeg')\n",
    "        index+=1\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#def augment(**kwargs):\n",
    "    #data_gen = ImageDataGenerator(\n",
    " #                           rotation_range = 30,\n",
    "  #                          width_shift_range=.3,\n",
    "   #                         height_shift_range=.4,\n",
    "    #                         shear_range=30,\n",
    "     #                        horizontal_flip=True,\n",
    "      #                       vertical_flip=True,\n",
    "       #                      zoom_range=0.2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def augment(images):    \n",
    "    os.mkdir('Images/augmented')\n",
    "    for image in images:\n",
    "        i = 0 \n",
    "        image = np.expand_dims(image,axis=0)\n",
    "        for batch in data_gen.flow(image, \n",
    "                           batch_size=1,\n",
    "                          save_to_dir='Images/augmented', \n",
    "                           save_prefix='tree', \n",
    "                           save_format='jpeg'):\n",
    "            i += 1 \n",
    "            if i > 20:\n",
    "                break\n",
    "\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagess = []\n",
    "for image in images:\n",
    "    if image[0:4] == 'data':\n",
    "        new = image.replace(\"data:image/jpeg;base64,\",\"\")\n",
    "        if new[-2:] != '==':\n",
    "            new_edit = new + '=='\n",
    "            image = (Image.open(BytesIO(base64.b64decode(new_edit)))).resize((150,150))\n",
    "            imagess.append(image)\n",
    "        else:\n",
    "            image = (Image.open(BytesIO(base64.b64decode(new)))).resize((150,150))\n",
    "            imagess.append(image)\n",
    "    if image[0:4] == 'http':\n",
    "        new = requests.get(image)\n",
    "        image = Image.open(BytesIO(image.content))\n",
    "        imagess.append(image)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary') \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, 150, 150)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
